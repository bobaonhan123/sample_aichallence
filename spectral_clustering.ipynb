{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e84e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =====================\n",
    "# CONFIGURATION\n",
    "# =====================\n",
    "DATA_DIR = \"./data\"       # Th∆∞ m·ª•c ·∫£nh, chia theo class kh√¥ng b·∫Øt bu·ªôc\n",
    "NUM_CLUSTERS = 5          # S·ªë c·ª•m c·∫ßn t√¨m\n",
    "USE_CNN_FEATURES = True   # True: tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng b·∫±ng ResNet18, False: d√πng trung b√¨nh m√†u\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# FEATURE EXTRACTION\n",
    "# =====================\n",
    "def extract_features(dataset, batch_size=32):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ·∫£nh b·∫±ng ResNet18 pre-trained.\n",
    "    \"\"\"\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "    model.fc = nn.Identity()  # B·ªè layer ph√¢n lo·∫°i cu·ªëi ƒë·ªÉ l·∫•y vector ƒë·∫∑c tr∆∞ng\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, _ in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            feat = model(imgs)\n",
    "            features.append(feat.cpu().numpy())\n",
    "\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "def extract_color_features(dataset):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng m√†u trung b√¨nh (3 gi√° tr·ªã R,G,B).\n",
    "    \"\"\"\n",
    "    color_features = []\n",
    "    for img, _ in tqdm(dataset, desc=\"Extracting color features\"):\n",
    "        arr = np.array(img).reshape(-1, 3)\n",
    "        color_features.append(arr.mean(axis=0))\n",
    "    return np.array(color_features)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# MAIN PIPELINE\n",
    "# =====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Spectral Clustering for Images\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\n",
    "    print(f\"Loaded {len(dataset)} images from {DATA_DIR}\")\n",
    "\n",
    "    # --- Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ---\n",
    "    if USE_CNN_FEATURES:\n",
    "        features = extract_features(dataset)\n",
    "    else:\n",
    "        features = extract_color_features(dataset)\n",
    "\n",
    "    print(f\"Feature shape: {features.shape}\")\n",
    "\n",
    "    # --- Chu·∫©n h√≥a d·ªØ li·ªáu ---\n",
    "    features_std = StandardScaler().fit_transform(features)\n",
    "\n",
    "    # --- √Åp d·ª•ng Spectral Clustering ---\n",
    "    print(\"\\nüîπ Running Spectral Clustering...\")\n",
    "    clustering = SpectralClustering(\n",
    "        n_clusters=NUM_CLUSTERS,\n",
    "        affinity='nearest_neighbors',  # Ho·∫∑c 'rbf' n·∫øu d·ªØ li·ªáu li√™n t·ª•c\n",
    "        n_neighbors=10,\n",
    "        assign_labels='kmeans',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    labels = clustering.fit_predict(features_std)\n",
    "\n",
    "    # --- ƒê√°nh gi√° b·∫±ng Silhouette Score ---\n",
    "    score = silhouette_score(features_std, labels)\n",
    "    print(f\"‚úÖ Silhouette Score = {score:.4f}\")\n",
    "\n",
    "    # --- Visualization b·∫±ng PCA ---\n",
    "    print(\"üìä Reducing dimensions for visualization...\")\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced = pca.fit_transform(features_std)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap=\"tab10\", s=20)\n",
    "    plt.title(\"Spectral Clustering Visualization (PCA 2D)\")\n",
    "    plt.xlabel(\"PCA 1\")\n",
    "    plt.ylabel(\"PCA 2\")\n",
    "    plt.colorbar(scatter, label=\"Cluster ID\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Hi·ªÉn th·ªã ·∫£nh ƒë·∫°i di·ªán m·ªói c·ª•m ---\n",
    "    print(\"\\nüñºÔ∏è Sample images per cluster:\")\n",
    "    samples_per_cluster = 3\n",
    "    img_paths = np.array(dataset.imgs)[:, 0]\n",
    "    for cluster_id in range(NUM_CLUSTERS):\n",
    "        cluster_indices = np.where(labels == cluster_id)[0]\n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "        chosen = np.random.choice(cluster_indices, min(samples_per_cluster, len(cluster_indices)), replace=False)\n",
    "\n",
    "        fig, axes = plt.subplots(1, len(chosen), figsize=(10, 3))\n",
    "        fig.suptitle(f\"Cluster {cluster_id}\", fontsize=14)\n",
    "        for i, idx in enumerate(chosen):\n",
    "            img, _ = dataset[idx]\n",
    "            axes[i].imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "            axes[i].axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    print(\"üéØ Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
